{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pyspark\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'household_power_consumption.txt'\n",
    "sc = pyspark.SparkContext(appName='sample_code_1')\n",
    "text_file = sc.textFile(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take_size = 3\n",
    "attr_idx = [2, 3]\n",
    "bc_attr_idx = sc.broadcast(attr_idx)\n",
    "bc_attr_idx.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date;Time;Global_active_power;Global_reactive_power;Voltage;Global_intensity;Sub_metering_1;Sub_metering_2;Sub_metering_3',\n",
       " '16/12/2006;17:24:00;4.216;0.418;234.840;18.400;0.000;1.000;17.000',\n",
       " '16/12/2006;17:25:00;5.360;0.436;233.630;23.000;0.000;1.000;16.000']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show data\n",
    "text_file.take(take_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[nan, nan], [4.216, 0.418], [5.36, 0.436]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_attrs(row):\n",
    "    attrs = row.split(';')\n",
    "    return np.take(attrs, bc_attr_idx.value)\n",
    "\n",
    "def trans_type(row):\n",
    "    try:\n",
    "        return [np.double(value) for value in row]\n",
    "    except:\n",
    "        return [np.nan] * len(row)\n",
    "\n",
    "text_file.map(get_attrs).map(trans_type).take(take_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.122,  1.39 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max(row1, row2):\n",
    "    stacked = np.vstack([row1, row2])\n",
    "    return np.nanmax(stacked, axis=0)\n",
    "\n",
    "text_file.map(get_attrs).map(trans_type).reduce(get_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: [11.122  1.39 ]\n",
      "time: 42.419591665267944\n"
     ]
    }
   ],
   "source": [
    "# dont believe this result \n",
    "\n",
    "start = time.time()\n",
    "result = text_file.map(get_attrs).map(trans_type).reduce(get_max)\n",
    "print('result: {}'.format(result))\n",
    "print('time: {}'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
