{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import linecache\n",
    "import csv\n",
    "from operator import add\n",
    "from pyspark.sql import SQLContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- IDLink: integer (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Headline: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Topic: string (nullable = true)\n",
      " |-- PublishDate: timestamp (nullable = true)\n",
      " |-- SentimentTitle: double (nullable = true)\n",
      " |-- SentimentHeadline: double (nullable = true)\n",
      " |-- Facebook: integer (nullable = true)\n",
      " |-- GooglePlus: integer (nullable = true)\n",
      " |-- LinkedIn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_name = './data/News_Final_1.csv'\n",
    "sc = pyspark.SparkContext(appName='hw2-3')\n",
    "text_file = sc.textFile(file_name)\n",
    "sqlContext=SQLContext(sc)\n",
    "news_data=sqlContext.read.format('csv')\\\n",
    "                    .option(\"header\", \"true\")\\\n",
    "                    .option(\"inferschema\", \"true\")\\\n",
    "                    .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "                    .load(file_name)\n",
    "news_data.printSchema()\n",
    "\n",
    "# news_data=news_data.withColumn('SentimentTitle', news_data['SentimentTitle'].cast('double'))\n",
    "# news_data=news_data.withColumn('SentimentHeadline', news_data['SentimentHeadline'].cast('double'))\n",
    "# news_data.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentScore=news_data.select('Topic', 'SentimentTitle', 'SentimentHeadline').rdd.map(list).map(lambda x:(x[0], [x[1], x[2], 1])).reduceByKey(lambda x, y:[x[0]+y[0], x[1]+y[1], x[2]+y[2]])\n",
    "SentimentScore_sum=SentimentScore.sortByKey(False).map(lambda x:[x[0], x[1][0], x[1][1]]).collect()\n",
    "SentimentScore_average=SentimentScore.sortByKey(False).map(lambda x:[x[0], x[1][0]/x[1][2], x[1][1]/x[1][2]]).collect()\n",
    "\n",
    "out=open('output/SentimentScore.txt','w')\n",
    "out.write('SentimentScore_sum\\n')\n",
    "print(SentimentScore_sum)\n",
    "for i in range(len(SentimentScore_sum)):\n",
    "    out.write(str(SentimentScore_sum[i]) + '\\n')\n",
    "out.write('\\nSentimentScore_average\\n')\n",
    "for i in range(len(SentimentScore_average)):\n",
    "    out.write(str(SentimentScore_average[i]) + '\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(file_name) as file:\n",
    "#     array = file.readlines()\n",
    "#     array = [row.split(',') for row in array]\n",
    "# for elm in array:\n",
    "#     print(elm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(array)):\n",
    "#     print(array[i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = sqlContext.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(file_name)\n",
    "\n",
    "# df.select(df['Topic'], df['SentimentTitle'], df['SentimentHeadline']).show()\n",
    "\n",
    "#df.show()\n",
    "\n",
    "\n",
    "# parts = text_file.map(lambda l:l.split(\",\"))\n",
    "# people = parts.map(lambda p:(p[6],p[6].strip()))\n",
    "\n",
    "# schemaString = \"SentimentTitle SentimentHeadline\"\n",
    "\n",
    "# fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
    "# schema = StructType(fields)\n",
    "\n",
    "# schemaPeople = sqlContext.createDataFrame(people, schema)\n",
    "\n",
    "# schemaPeople.registerTempTable(\"people\")\n",
    "\n",
    "# results = sqlContext.sql(\"SELECT SentimentTitle from people\")\n",
    "\n",
    "# STs = results.rdd.map(lambda p:\"SentimentTitle: \" + p.SentimentTitle)\n",
    "\n",
    "# for st in STs.collect():\n",
    "#     print(st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
